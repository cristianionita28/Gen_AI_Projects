{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a71164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SymSpell…\n",
      "Loading BERT model… (first run takes ~10 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using default text:\n",
      " Thiss cod chekks speling in text using SymSpell and BERRT ranking.\n",
      "It corects words by two stepps: dictionnary lookup and conttext moddel.\n",
      "SymmSpell findd candidattes from a big dictonary faast.\n",
      "Then a BERRT maskked language modele chooces the best suggetion in context.\n",
      "The input can be a defaalt texxt or custtom lines typped by the usser.\n",
      "In the defalt texxt we add mispelled wordss to testt the code.\n",
      "This codee prints the correced texte and a raport of all wrong wordt.\n",
      "Only CPU ussage is needded, usingg a smaler BERT model for speeed.\n",
      "\n",
      "Correcting text using SymSpell + BERT…\n",
      "\n",
      "---------------------------------------\n",
      "Corrected Text:\n",
      "---------------------------------------\n",
      "This cod checks spelling in text using Spell and BERRY ranking.\n",
      "It corrects words by two steps: dictionary lookup and context model.\n",
      "SymmSpell find candidates from a big dictionary fast.\n",
      "Then a BERRY masked language model choices the best suggestion in context.\n",
      "The input can be a default text or custom lines typed by the user.\n",
      "In the default text we add misspelled words to test the code.\n",
      "This code prints the corrected text and a report of all wrong words.\n",
      "Only CUP usage is needed, using a smaller BERT model for speed.\n",
      "\n",
      "---------------------------------------\n",
      "Correction Report:\n",
      "---------------------------------------\n",
      "Thiss → This\n",
      "chekks → checks\n",
      "speling → spelling\n",
      "SymSpell → Spell\n",
      "BERRT → BERRY\n",
      "corects → corrects\n",
      "stepps → steps\n",
      "dictionnary → dictionary\n",
      "conttext → context\n",
      "moddel → model\n",
      "findd → find\n",
      "candidattes → candidates\n",
      "dictonary → dictionary\n",
      "faast → fast\n",
      "maskked → masked\n",
      "modele → model\n",
      "chooces → choices\n",
      "suggetion → suggestion\n",
      "defaalt → default\n",
      "texxt → text\n",
      "custtom → custom\n",
      "typped → typed\n",
      "usser → user\n",
      "defalt → default\n",
      "mispelled → misspelled\n",
      "wordss → words\n",
      "testt → test\n",
      "codee → code\n",
      "correced → corrected\n",
      "texte → text\n",
      "raport → report\n",
      "wordt → words\n",
      "CPU → CUP\n",
      "ussage → usage\n",
      "needded → needed\n",
      "usingg → using\n",
      "smaler → smaller\n",
      "speeed → speed\n",
      "\n",
      "Total corrected words: 38\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "from pkg_resources import resource_filename\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1. Load SymSpell dictionary\n",
    "# --------------------------------------------------------\n",
    "def load_symspell(max_distance=3):\n",
    "    sym_spell = SymSpell(max_dictionary_edit_distance=max_distance, prefix_length=7)\n",
    "\n",
    "    # Try to load dictionary packaged inside symspellpy\n",
    "    try:\n",
    "        dictionary_path = resource_filename(\n",
    "            \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
    "        )\n",
    "    except Exception:\n",
    "        dictionary_path = \"frequency_dictionary_en_82_765.txt\"\n",
    "\n",
    "    if not os.path.exists(dictionary_path):\n",
    "        print(f\"[ERROR] Dictionary not found at: {dictionary_path}\")\n",
    "        print(\n",
    "            \"Download: https://raw.githubusercontent.com/mammothb/symspellpy/master/symspellpy/frequency_dictionary_en_82_765.txt\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "\n",
    "    sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "    return sym_spell\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. Load BERT Masked-LM model\n",
    "# --------------------------------------------------------\n",
    "def load_bert():\n",
    "    return pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. Smart contextual ranking with BERT\n",
    "# --------------------------------------------------------\n",
    "def choose_best_with_bert(bert, sentence, target_word, candidates):\n",
    "    \"\"\"\n",
    "    Replace target_word with [MASK], ask BERT which candidate fits the context.\n",
    "    \"\"\"\n",
    "    masked = sentence.replace(target_word, \"[MASK]\", 1)\n",
    "\n",
    "    # Query BERT\n",
    "    outputs = bert(masked)\n",
    "\n",
    "    # Format:\n",
    "    # [{'sequence': '...', 'score': ..., 'token_str': 'this'}, ...]\n",
    "    scores = {entry[\"token_str\"]: entry[\"score\"] for entry in outputs}\n",
    "\n",
    "    # Normalize candidates (lowercase BERT tokens)\n",
    "    def normalize(w):\n",
    "        return w.lower()\n",
    "\n",
    "    ranked = []\n",
    "    for cand in candidates:\n",
    "        c = normalize(cand)\n",
    "        ranked.append((cand, scores.get(c, 0)))  # 0 if BERT didn't propose it\n",
    "\n",
    "    # Sort by BERT contextual probability\n",
    "    ranked.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return ranked[0][0]  # best candidate\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4. Capitalization helper\n",
    "# --------------------------------------------------------\n",
    "def apply_original_casing(original, corrected):\n",
    "    if original.isupper():\n",
    "        return corrected.upper()\n",
    "    if original[0].isupper():\n",
    "        return corrected.capitalize()\n",
    "    return corrected\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5. Full correction logic\n",
    "# --------------------------------------------------------\n",
    "def correct_text(sym_spell, bert, text):\n",
    "    # Tokenize while keeping punctuation\n",
    "    tokens = re.findall(r\"[A-Za-z']+|[^A-Za-z']+\", text)\n",
    "    corrected_tokens = tokens.copy()\n",
    "    corrections = {}\n",
    "\n",
    "    # Rebuild text by sentences (for contextual BERT)\n",
    "    sentences = re.split(r\"(?<=[.!?]) +\", text)\n",
    "\n",
    "    for s_idx, sentence in enumerate(sentences):\n",
    "        words = re.findall(r\"[A-Za-z']+\", sentence)\n",
    "\n",
    "        for word in words:\n",
    "            lookup = sym_spell.lookup(\n",
    "                word.lower(), Verbosity.CLOSEST, max_edit_distance=3\n",
    "            )\n",
    "\n",
    "            if not lookup:\n",
    "                continue\n",
    "\n",
    "            # top N SymSpell suggestions\n",
    "            candidates = [cand.term for cand in lookup[:5]]\n",
    "\n",
    "            # If the original is included → skip\n",
    "            if word.lower() in candidates:\n",
    "                continue\n",
    "\n",
    "            # Use BERT to pick best suggestion given context\n",
    "            best = choose_best_with_bert(bert, sentence, word, candidates)\n",
    "\n",
    "            # Apply original casing\n",
    "            best = apply_original_casing(word, best)\n",
    "\n",
    "            # Replace exactly in the reconstructed text\n",
    "            for i, tok in enumerate(corrected_tokens):\n",
    "                if tok == word:\n",
    "                    corrected_tokens[i] = best\n",
    "\n",
    "            corrections[word] = best\n",
    "\n",
    "    final_text = \"\".join(corrected_tokens)\n",
    "    return final_text, corrections\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 6. User input logic\n",
    "# --------------------------------------------------------\n",
    "default_text = (\n",
    "    \"Thiss cod chekks speling in text using SymSpell and BERRT ranking.\\n\"\n",
    "    \"It corects words by two stepps: dictionnary lookup and conttext moddel.\\n\"\n",
    "    \"SymmSpell findd candidattes from a big dictonary faast.\\n\"\n",
    "    \"Then a BERRT maskked language modele chooces the best suggetion in context.\\n\"\n",
    "    \"The input can be a defaalt texxt or custtom lines typped by the usser.\\n\"\n",
    "    \"In the defalt texxt we add mispelled wordss to testt the code.\\n\"\n",
    "    \"This codee prints the correced texte and a raport of all wrong wordt.\\n\"\n",
    "    \"Only CPU ussage is needded, usingg a smaler BERT model for speeed.\"\n",
    ")\n",
    "\n",
    "\n",
    "def get_text():\n",
    "    choice = input(\"Use default text? (yes/no): \").strip().lower()\n",
    "    if choice == \"yes\":\n",
    "        print(\"\\nUsing default text:\\n\", default_text)\n",
    "        return default_text\n",
    "\n",
    "    print(\"\\nEnter your text (finish with empty line):\")\n",
    "    lines = []\n",
    "    while True:\n",
    "        line = input()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        lines.append(line)\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 7. Main\n",
    "# --------------------------------------------------------\n",
    "def main():\n",
    "    print(\"Loading SymSpell…\")\n",
    "    sym_spell = load_symspell()\n",
    "\n",
    "    print(\"Loading BERT model… (first run takes ~10 sec)\")\n",
    "    bert = load_bert()\n",
    "\n",
    "    text = get_text()\n",
    "\n",
    "    print(\"\\nCorrecting text using SymSpell + BERT…\")\n",
    "    corrected, report = correct_text(sym_spell, bert, text)\n",
    "\n",
    "    print(\"\\n---------------------------------------\")\n",
    "    print(\"Corrected Text:\")\n",
    "    print(\"---------------------------------------\")\n",
    "    print(corrected)\n",
    "\n",
    "    print(\"\\n---------------------------------------\")\n",
    "    print(\"Correction Report:\")\n",
    "    print(\"---------------------------------------\")\n",
    "    for wrong, correct in report.items():\n",
    "        print(f\"{wrong} → {correct}\")\n",
    "\n",
    "    print(f\"\\nTotal corrected words: {len(report)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
