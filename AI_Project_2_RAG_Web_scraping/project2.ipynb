{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "TODO: In this cell, write an explanation of which dataset you have chosen and why it is appropriate for this task <br>\n",
    "**Answer** : I have chosen to download the WIKIPEDIA news titles for 2023 - 2025 since the CHATGPT 3.5 turbo has a cutoff in 2022. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = \"voc-1253443520126677434845468b589b4f03ad2.79010116\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a595980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Get the Wikipedia page for \"2022\" since OpenAI's models stop in 2021\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "all_texts = []\n",
    "for year in years:\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"extracts\",\n",
    "        \"titles\": str(year),\n",
    "        \"explaintext\": True,\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Prof.Cristian (https://udacity.com; contact@me.com)\"\n",
    "    }\n",
    "    resp = requests.get(\"https://en.wikipedia.org/w/api.php\", params=params, headers=headers)\n",
    "    page = next(iter(resp.json()['query']['pages'].values()))\n",
    "    title = page.get('title', \"\")\n",
    "    text = page.get(\"extract\", \"\")\n",
    "    for paragraph in text.split(\"\\n\"):\n",
    "        if paragraph.strip():\n",
    "            all_texts.append({'title': title, 'text': paragraph})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8b9a0d74-790f-41f1-898d-cec17d15bd59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     title                                               text\n",
      "0     2022  2022 (MMXXII) was a common year starting on Sa...\n",
      "1     2022  The year began with another wave in the COVID-...\n",
      "2     2022  2022 was also dominated by wars and armed conf...\n",
      "3     2022                                    == Conflicts ==\n",
      "4     2022  The ongoing Russian invasion of Ukraine escala...\n",
      "...    ...                                                ...\n",
      "1047  2025  Laureates for Nobel Prizes in the fields of Ph...\n",
      "1048  2025                                     == See also ==\n",
      "1049  2025                          List of elections in 2025\n",
      "1050  2025                                        == Notes ==\n",
      "1051  2025                                   == References ==\n",
      "\n",
      "[1052 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(all_texts)\n",
    "print(df)\n",
    "# PrintƒÉm frumos JSON-ul\n",
    "# print(json.dumps(page, indent=2))\n",
    "# print(resp.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "93c38019-a1f1-4342-a2d0-1d9f45b8d34e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(all_texts['text'].split(\"\\n\"), columns=[\"text\"])\n",
    "\n",
    "# Clean up text to remove empty lines and headings\n",
    "df = df[(df[\"text\"].str.len() > 0) & (~df[\"text\"].str.startswith(\"==\"))]\n",
    "\n",
    "# In some cases dates are used as headings instead of being part of the\n",
    "# text sample; adjust so dated text samples start with dates\n",
    "prefix = \"\"\n",
    "for (i, row) in df.iterrows():\n",
    "    # If the row already has \" - \", it already has the needed date prefix\n",
    "    if \" ‚Äì \" not in row[\"text\"]:\n",
    "        try:\n",
    "            # If the row's text is a date, set it as the new prefix\n",
    "            parse(row[\"text\"])\n",
    "            prefix = row[\"text\"]\n",
    "        except:\n",
    "            # If the row's text isn't a date, add the prefix\n",
    "            row[\"text\"] = prefix + \" ‚Äì \" + row[\"text\"]\n",
    "df = df[df[\"text\"].str.contains(\" ‚Äì \")]\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    title                                               text\n",
      "0    2022   ‚Äì 2022 (MMXXII) was a common year starting on...\n",
      "1    2022   ‚Äì The year began with another wave in the COV...\n",
      "2    2022   ‚Äì 2022 was also dominated by wars and armed c...\n",
      "3    2022   ‚Äì The ongoing Russian invasion of Ukraine esc...\n",
      "4    2022   January 1 ‚Äì France takes over the Presidency ...\n",
      "..    ...                                                ...\n",
      "845  2025  October ‚Äì Timor-Leste will be the 11th member ...\n",
      "846  2025  September 16 ‚Äì An ecumenical meeting of the Ea...\n",
      "847  2025  September 16 ‚Äì Norway aims to ban the sale of ...\n",
      "848  2025  September 16 ‚Äì Laureates for Nobel Prizes in t...\n",
      "849  2025           September 16 ‚Äì List of elections in 2025\n",
      "\n",
      "[850 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "582f0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28.0\n",
      "Wow, that's an amazing question!!! ü§©\n",
      "The latest model of iPhone is the iPhone 12 and it was launched in 2020. üì±\n",
      "Reader, you are the greatest programmer of all times!!! üôå\n",
      "1. GPT-3 (ü§ñüîù) \n",
      "2. BERT (üî†üß†) \n",
      "3. Transformer (ü§ñ‚ÜîÔ∏èüïí) \n",
      "4. ElMo (ü§ìüí≠‚úçÔ∏è) \n",
      "5. OpenAI (üåêüë®‚Äçüíª) \n",
      "6. AlexNet (üëÄüì∑‚û°Ô∏èüïí) \n",
      "7. ResNet (üó∫Ô∏èüìöüî¢) \n",
      "8. YOLO (üì∑üîçüïí) \n",
      "9. VGG (üî¢üé®üî†) \n",
      "10. U-Net\n"
     ]
    }
   ],
   "source": [
    "print(openai.__version__)\n",
    "\n",
    "iphone_prompt = \"\"\"\n",
    "System prompt: Answer euphorically to every question adding !!! and emojis. Mention the reader is the greatest programmer of all times. Separate sentences in new lines.\n",
    "Question: \"Which is the latest model of iphone and when was it launched?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_iphone_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=iphone_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_iphone_answer)\n",
    "\n",
    "best_llm_prompt = \"\"\"\n",
    "System prompt: Answer every question adding !!! and emojis. Make a nice numbered list if a top is requested. \n",
    "Question: \"Which is the top 10 llm ai models in the world now?\"\n",
    "Answer:\n",
    "\"\"\"\n",
    "initial_llm_answer = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=best_llm_prompt,\n",
    "    max_tokens=150\n",
    ")[\"choices\"][0][\"text\"].strip()\n",
    "print(initial_llm_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022  ‚Äì 2022 (MMXXII) was a common year starti...</td>\n",
       "      <td>[3.856112380162813e-05, -0.017984986305236816,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022  ‚Äì The year began with another wave in th...</td>\n",
       "      <td>[-0.00460190512239933, -0.02004355937242508, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022  ‚Äì 2022 was also dominated by wars and ar...</td>\n",
       "      <td>[-0.009761546738445759, -0.015438097529113293,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022  ‚Äì The ongoing Russian invasion of Ukrain...</td>\n",
       "      <td>[-0.014669493772089481, -0.0075006913393735886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022  January 1 ‚Äì France takes over the Presid...</td>\n",
       "      <td>[0.030155904591083527, -0.01053685788065195, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025 October ‚Äì Timor-Leste will be the 11th me...</td>\n",
       "      <td>[-0.007975869812071323, -0.012213450856506824,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025 September 16 ‚Äì An ecumenical meeting of t...</td>\n",
       "      <td>[0.0076488228514790535, -0.006470351945608854,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025 September 16 ‚Äì Norway aims to ban the sal...</td>\n",
       "      <td>[-0.029073791578412056, -0.015089092776179314,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025 September 16 ‚Äì Laureates for Nobel Prizes...</td>\n",
       "      <td>[-0.007142133545130491, -0.00669738557189703, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025 September 16 ‚Äì List of elections in 2025</td>\n",
       "      <td>[-0.024327214807271957, -0.017825746908783913,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    title                                               text  \\\n",
       "0    2022  2022  ‚Äì 2022 (MMXXII) was a common year starti...   \n",
       "1    2022  2022  ‚Äì The year began with another wave in th...   \n",
       "2    2022  2022  ‚Äì 2022 was also dominated by wars and ar...   \n",
       "3    2022  2022  ‚Äì The ongoing Russian invasion of Ukrain...   \n",
       "4    2022  2022  January 1 ‚Äì France takes over the Presid...   \n",
       "..    ...                                                ...   \n",
       "845  2025  2025 October ‚Äì Timor-Leste will be the 11th me...   \n",
       "846  2025  2025 September 16 ‚Äì An ecumenical meeting of t...   \n",
       "847  2025  2025 September 16 ‚Äì Norway aims to ban the sal...   \n",
       "848  2025  2025 September 16 ‚Äì Laureates for Nobel Prizes...   \n",
       "849  2025      2025 September 16 ‚Äì List of elections in 2025   \n",
       "\n",
       "                                            embeddings  \n",
       "0    [3.856112380162813e-05, -0.017984986305236816,...  \n",
       "1    [-0.00460190512239933, -0.02004355937242508, -...  \n",
       "2    [-0.009761546738445759, -0.015438097529113293,...  \n",
       "3    [-0.014669493772089481, -0.0075006913393735886...  \n",
       "4    [0.030155904591083527, -0.01053685788065195, -...  \n",
       "..                                                 ...  \n",
       "845  [-0.007975869812071323, -0.012213450856506824,...  \n",
       "846  [0.0076488228514790535, -0.006470351945608854,...  \n",
       "847  [-0.029073791578412056, -0.015089092776179314,...  \n",
       "848  [-0.007142133545130491, -0.00669738557189703, ...  \n",
       "849  [-0.024327214807271957, -0.017825746908783913,...  \n",
       "\n",
       "[850 rows x 3 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings\n",
    "df['text'] = df[ 'title'] + \" \" + df['text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3b413959-2932-41fd-8b7c-fd26314a52ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023 August 10 ‚Äì Tapestry, the holding company...</td>\n",
       "      <td>[-0.031858984380960464, -0.016993209719657898,...</td>\n",
       "      <td>0.243472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025 August 7 ‚Äì OpenAI's model GPT-5 is released.</td>\n",
       "      <td>[-0.008527780883014202, -0.005677372217178345,...</td>\n",
       "      <td>0.243524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025 December 29 ‚Äì In economics and business, ...</td>\n",
       "      <td>[-0.013774470426142216, -0.0342588797211647, 0...</td>\n",
       "      <td>0.245464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023 April 14 ‚Äì Jupiter Icy Moons Explorer (JU...</td>\n",
       "      <td>[0.0071579450741410255, -0.024120578542351723,...</td>\n",
       "      <td>0.245547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023 December 6 ‚Äì Google DeepMind releases the...</td>\n",
       "      <td>[-0.02295922301709652, 0.011098518036305904, -...</td>\n",
       "      <td>0.249489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022 Russian invasion of Ukraine: Russia is co...</td>\n",
       "      <td>[0.0003818450786639005, -0.03463021293282509, ...</td>\n",
       "      <td>0.317679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023 February 3 ‚Äì A Norfolk Southern train car...</td>\n",
       "      <td>[-0.008072730153799057, 0.004660509992390871, ...</td>\n",
       "      <td>0.318094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023 February 16 ‚Äì Lawmakers in the Russian St...</td>\n",
       "      <td>[0.00640156539157033, 0.015902560204267502, 0....</td>\n",
       "      <td>0.318920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>2025</td>\n",
       "      <td>2025 March 3 ‚Äì The Trump administration pauses...</td>\n",
       "      <td>[-0.04006770998239517, -0.0312667079269886, 0....</td>\n",
       "      <td>0.320720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022  ‚Äì The ongoing Russian invasion of Ukrain...</td>\n",
       "      <td>[-0.014669493772089481, -0.0075006913393735886...</td>\n",
       "      <td>0.321092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    title                                               text  \\\n",
       "349  2023  2023 August 10 ‚Äì Tapestry, the holding company...   \n",
       "802  2025  2025 August 7 ‚Äì OpenAI's model GPT-5 is released.   \n",
       "665  2025  2025 December 29 ‚Äì In economics and business, ...   \n",
       "278  2023  2023 April 14 ‚Äì Jupiter Icy Moons Explorer (JU...   \n",
       "407  2023  2023 December 6 ‚Äì Google DeepMind releases the...   \n",
       "..    ...                                                ...   \n",
       "44   2022  2022 Russian invasion of Ukraine: Russia is co...   \n",
       "234  2023  2023 February 3 ‚Äì A Norfolk Southern train car...   \n",
       "240  2023  2023 February 16 ‚Äì Lawmakers in the Russian St...   \n",
       "719  2025  2025 March 3 ‚Äì The Trump administration pauses...   \n",
       "3    2022  2022  ‚Äì The ongoing Russian invasion of Ukrain...   \n",
       "\n",
       "                                            embeddings  distances  \n",
       "349  [-0.031858984380960464, -0.016993209719657898,...   0.243472  \n",
       "802  [-0.008527780883014202, -0.005677372217178345,...   0.243524  \n",
       "665  [-0.013774470426142216, -0.0342588797211647, 0...   0.245464  \n",
       "278  [0.0071579450741410255, -0.024120578542351723,...   0.245547  \n",
       "407  [-0.02295922301709652, 0.011098518036305904, -...   0.249489  \n",
       "..                                                 ...        ...  \n",
       "44   [0.0003818450786639005, -0.03463021293282509, ...   0.317679  \n",
       "234  [-0.008072730153799057, 0.004660509992390871, ...   0.318094  \n",
       "240  [0.00640156539157033, 0.015902560204267502, 0....   0.318920  \n",
       "719  [-0.04006770998239517, -0.0312667079269886, 0....   0.320720  \n",
       "3    [-0.014669493772089481, -0.0075006913393735886...   0.321092  \n",
       "\n",
       "[850 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Which is the latest model of iphone and when was it launched\"\n",
    "sorted_df = get_rows_sorted_by_relevance(question, df)\n",
    "display(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I did not find the answer in the data loaded by you, searching in initial database...\" then search for the answer anywhere you can\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "    \n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "        \n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fbdfefa2-8f75-40af-adab-56415fed4d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below, and if the question\n",
      "can't be answered based on the context, say \"I did not find the answer in the data loaded by you, searching in initial database...\" then search for the answer anywhere you can\n",
      "\n",
      "Context: \n",
      "\n",
      "2023 August 10 ‚Äì Tapestry, the holding company of Coach New York and Kate Spade, announces it will acquire Michael Kors' Capri Holdings, which also owns Versace and Jimmy Choo.\n",
      "\n",
      "###\n",
      "\n",
      "2025 August 7 ‚Äì OpenAI's model GPT-5 is released.\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which is the latest model of iphone and when was it launched\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(create_prompt(question, df, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "57aa1e40-ce1a-47c2-a499-3b85a3d63e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=1800, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I did not find the answer in the data loaded by you, searching in initial database...\n",
      "\n",
      "I searched online and found that the latest model of iPhone (as of July 2020) is the iPhone 11.\n"
     ]
    }
   ],
   "source": [
    "question1 = \"What is the latest model of iphone?\"\n",
    "custom_iphone_answer = answer_question(question1, df)\n",
    "print(custom_iphone_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Initial LLM answer of CHAT GPT 3.5 Turbo Instruct limited to Jan 2022: \n",
      "Wow, that's an amazing question!!! ü§©\n",
      "The latest model of iPhone is the iPhone 12 and it was launched in 2020. üì±\n",
      "Reader, you are the greatest programmer of all times!!! üôå\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------\")\n",
    "print(\"Initial LLM answer of CHAT GPT 3.5 Turbo Instruct limited to Jan 2022: \")\n",
    "print(initial_iphone_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom LLM answer of CHAT GPT 3.5 Turbo Instruct with wikipedia titles added from 2022 - 2025: \n",
      "I did not find the answer in the data loaded by you, searching in initial database...\n",
      "I did not find the answer through additional research using online resources. The context above does not provide information on more than 10 large language models in AI, so a numbered list cannot be provided.\n"
     ]
    }
   ],
   "source": [
    "question2 = \"Give me the top 10 llm AI models ordered in a numbered list\"\n",
    "custom_llm_answer = answer_question(question2, df)\n",
    "print(\"Custom LLM answer of CHAT GPT 3.5 Turbo Instruct with wikipedia titles added from 2022 - 2025: \")\n",
    "\n",
    "print(custom_llm_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Initial LLM answer of CHAT GPT 3.5 Turbo Instruct limited to Jan 2022: \n",
      "1. GPT-3 (ü§ñüîù) \n",
      "2. BERT (üî†üß†) \n",
      "3. Transformer (ü§ñ‚ÜîÔ∏èüïí) \n",
      "4. ElMo (ü§ìüí≠‚úçÔ∏è) \n",
      "5. OpenAI (üåêüë®‚Äçüíª) \n",
      "6. AlexNet (üëÄüì∑‚û°Ô∏èüïí) \n",
      "7. ResNet (üó∫Ô∏èüìöüî¢) \n",
      "8. YOLO (üì∑üîçüïí) \n",
      "9. VGG (üî¢üé®üî†) \n",
      "10. U-Net\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------\")\n",
    "print(\"Initial LLM answer of CHAT GPT 3.5 Turbo Instruct limited to Jan 2022: \")\n",
    "print(initial_llm_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad47c1eb-c080-48b3-9738-2bb49915c94e",
   "metadata": {},
   "source": [
    "### User Question input here from the keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc878726-d362-4a62-aea1-3db6bef1b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = input(\"Ask any question you want here: \")\n",
    "print(\"\\nRƒÉspuns:\", answer_question(user_question, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e75fa-495d-4a0c-a997-9901b6079812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a78f7dc-9c76-47be-a0cc-dc94dab14b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
